{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c897773",
   "metadata": {},
   "source": [
    "### Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823a2cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a DataFrame\n",
    "df[['Name', 'PID']]\n",
    "# Rows where Name includes 'on'\n",
    "df.loc[df['Name'].str.contains('on')]\n",
    "# Rows where the first letter of Name is between A and L\n",
    "df[dfs['Name'] < 'M']\n",
    "ser.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06331b20",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "- NumPy enables **fast** computation involving arrays and matrices. **(optimized for speed and memory consumption.)**\n",
    "- `numpy`'s main object is the **array**. In `numpy`, arrays are:\n",
    "    - homogenous (all values are of the same type) -- leads to **type coercion**\n",
    "    - (potentially) multi-dimensional.\n",
    "- Computation in `numpy` is fast because\n",
    "    - Much of it is implemented in C.\n",
    "    - `numpy` arrays are stored more efficiently in memory than Python lists. \n",
    "- count(), unique(), nunique(), value_counts(normalize = ) *Returns a Series of counts of unique values*, describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5900bf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " `pandas` is built upon `numpy` **(slow and use a lot of memory, but optimize for fast code development.)**\n",
    "\n",
    "- A Series in `pandas` is a `numpy` array with an index.\n",
    "- A DataFrame is like a dictionary of columns, each of which is a `numpy` array.\n",
    "- Many operations in `pandas` are fast because they use `numpy`'s implementations.\n",
    "- To access the array underlying a DataFrame or Series, use the `to_numpy` method.\n",
    "    - ⚠️ Warning: `to_numpy` returns a view of the original object, not a copy! , also change the original series\n",
    "    - `.values` is a soon-to-be-deprecated version of `.to_numpy()`.\n",
    "- sort_values('name', ascending = False), drop_duplicates(subset = ['a', 'b']), drop(columns = [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948f0fd8",
   "metadata": {},
   "source": [
    "### Messy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b4569f",
   "metadata": {},
   "outputs": [],
   "source": [
    "students['2021 tuition'].str.strip('$').astype(float)\n",
    "students['Paid'].replace({'Y': True, 'N': False})\n",
    "pd.to_numeric(students['DSC 80 Final Grade'], errors='coerce') #convert to digit where string is converted to NaN\n",
    "parts = students['Student Name'].str.split()\n",
    "df['name'] = parts.str[1] + ', ' + parts.str[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852b7360",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Outliers\n",
    "* **Consistently \"incorrect\" values**. Recorded ages of -1 or 99.\n",
    "    - Solution: Change the value to the correct one if it is known!\n",
    "* **Abnormal artifacts from the data collection process**.\n",
    "    - Example: Spikes in recorded ages at round numbers (25, 30, 35, 40), or spikes in recorded COVID cases on Mondays.\n",
    "    - Solution: Try \"smoothing\", e.g. binning the ages.\n",
    "* **Unreasonable outliers**. Example: Age of 200.\n",
    "    - Solution: Not sure. Could remove the row. Could be indicative of a bug in the data collection process. Could be real!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4fe44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All of the rows where the subject age is missing\n",
    "stops[stops['subject_age'].isna()]\n",
    "# fill nan with column means\n",
    "nans.agg(lambda x: x.fillna(x.mean()), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4ef9b6",
   "metadata": {},
   "source": [
    "* `.dropna()` drops **rows** containing **at least one** null value.\n",
    "* `.dropna(how='all')` drops **rows** containing **only** null values.\n",
    "* `.dropna(axis=1)` drops **columns** containing at least one null value.\n",
    "* `.fillna(val)` fills null entries with the value `val`.\n",
    "* `.fillna(dict)` fills null entries using a dictionary `dict` to fill NaNs differently for each column\n",
    "* `.fillna(method='bfill')` and `.fillna(method='ffill')` fill null entries using neighboring non-null entries.\n",
    "\n",
    "`NaN` is of type `float` !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195e9c31",
   "metadata": {},
   "source": [
    "### Hypothesis Testing (assess a model given a single random sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819db75d",
   "metadata": {},
   "source": [
    "* two distributions are **categorical** distributions, use TVD\n",
    "* two distributions are **numerical** distributions, use difference in group means or medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f80867",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.random.choice([1, 0], p=[0.55, 0.45], size=(N, 114)) # numerical, return N rows, 114 cols\n",
    "np.sum(np.abs(series1 - series2)) / 2 #TVD for two series\n",
    "temp = np.random.multinomial(N, [0.1, 0.4, 0.5], size=num_reps) / N # categorical simulations, return num_reps rows\n",
    "np.sum(np.abs(temp - eth['California'].to_numpy()), axis=1) / 2 #TVD for an array of arrays & a series\n",
    "(np.array(results) >= obs).mean() # p-value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628ad8dd",
   "metadata": {},
   "source": [
    "### Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cc25fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins.groupby('species')['body_mass_g'].aggregate(['count', 'mean'])\n",
    "penguins.groupby('species').aggregate({'bill_length_mm': 'max', 'island': 'nunique'})\n",
    "np.percentile(col, 75) - np.percentile(col, 25) #IQR\n",
    "penguins.groupby('species')['body_mass_g'].transform(lambda ser: ser - ser.mean()) #returns Series of the same size\n",
    "penguins.groupby('species').filter(lambda df: df['bill_length_mm'].mean() > 39) #filter out a group of species\n",
    "#One row for every unique value in index, one col for every unique value in columns\n",
    "penguins.pivot_table(index='species', \n",
    "                     columns='island', \n",
    "                     values='body_mass_g', \n",
    "                     aggfunc='mean',\n",
    "                     fill_value = 0) #aggfunc: count, mean, max, sum, size..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4d94a9",
   "metadata": {},
   "source": [
    "### Combining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1df9657",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ed59497",
   "metadata": {},
   "source": [
    "### Permutation (compare two random samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037edc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test statistic - difference in group means\n",
    "observed_difference = (smoking_and_birthweight.groupby('Maternal Smoker')['Birth Weight'].mean().diff().iloc[-1])\n",
    "for _ in range(n_repetitions): #normal approach \n",
    "    # Step 1: Shuffle the weights\n",
    "    shuffled_weights = np.random.permutation(weights)   \n",
    "    # Step 2: Put them in a DataFrame\n",
    "    to_shuffle['Shuffled Birth Weight'] = shuffled_weights  \n",
    "    # Step 3: Compute the test statistic\n",
    "    group_means = (\n",
    "        to_shuffle\n",
    "        .groupby('Maternal Smoker')\n",
    "        .mean()\n",
    "        .loc[:, 'Shuffled Birth Weight']\n",
    "    )\n",
    "    difference = group_means.diff().iloc[-1]  \n",
    "    # Step 4: Store the result\n",
    "    faster_differences.append(difference)\n",
    "pval = (difference >= obs_diff).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbe85b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#faster approach\n",
    "is_smoker = smoking_and_birthweight['Maternal Smoker'].values #boolean array\n",
    "weights = smoking_and_birthweight['Birth Weight'].values  #boolean array\n",
    "n_smokers = is_smoker.sum()\n",
    "n_non_smokers = 1174 - n_smokers\n",
    "\n",
    "is_smoker_permutations = np.column_stack([\n",
    "    np.random.permutation(is_smoker)\n",
    "    for _ in range(3000)\n",
    "]).T\n",
    "\n",
    "mean_smokers = (weights * is_smoker_permutations).sum(axis=1) / n_smokers\n",
    "mean_non_smokers = (weights * ~is_smoker_permutations).sum(axis=1) / n_non_smokers\n",
    "ultra_fast_differences = mean_smokers - mean_non_smokers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceef395e",
   "metadata": {},
   "source": [
    "### Missingness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcc46a3",
   "metadata": {},
   "source": [
    "MD - can i determine the missing value exactly by looking at other col?  \n",
    "NMAR - is there a good reason why the messingness depend on value itself?  \n",
    "MAR - do other cols tell me the likelihood that a value is missing?  \n",
    "MCAR - missingness does not depent on value nor other cols. Can perform listwise deletion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2facbc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- use permutation tests to verify if a column is MAR vs. MCAR.\n",
    "    - Create two groups: one where values in a column are missing, and another where values in a column aren't missing.\n",
    "    - To test the missingness of column X:\n",
    "        - For every other column, test the null hypothesis \"the distribution of (other column) is the same when column X is missing and when column X is not missing.\"\n",
    "        - If you fail to reject the null, then column X's missingness does not depend on (other column).\n",
    "        - If you reject the null, then column X is MAR dependent on (other column).\n",
    "        - **If you fail to reject the null for all other columns, then column X is MCAR!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7753911",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
